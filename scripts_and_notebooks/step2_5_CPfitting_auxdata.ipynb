{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prob_ncm(scores, labels):\n",
    "    \"\"\"\n",
    "    Converts Neural Network scores into Nonconformity Measures for CP.\n",
    "    Assumes that scores are directly related to the probability of being active\n",
    "    \"\"\"\n",
    "    return np.where( labels > 0, -scores, scores )\n",
    "\n",
    "### p-Values calculation\n",
    "def p_values(calibration_alphas, test_alphas, randomized=False):\n",
    "    sorted_cal_alphas = sorted(calibration_alphas)\n",
    "    if randomized:\n",
    "        # for each test alpha, tieBreaker is the (number of calibration alphas with the same value)*(uniform RV between 0 and 1)\n",
    "        tie_counts = np.searchsorted(sorted_cal_alphas,test_alphas,side='right')-np.searchsorted(sorted_cal_alphas,test_alphas)\n",
    "        tie_breaker = np.random.uniform(size=len(np.atleast_1d(test_alphas)))*tie_counts\n",
    "        return  (len(calibration_alphas)-(np.searchsorted(sorted_cal_alphas,test_alphas,side='right')-tie_breaker)+1)/(len(calibration_alphas)+1)\n",
    "    else:\n",
    "        return  (len(calibration_alphas)-np.searchsorted(sorted_cal_alphas,test_alphas)+1)/(len(calibration_alphas)+1)\n",
    "\n",
    "# Mondrian Inductive Conformal Predictor\n",
    "def micp(calibration_alphas,calibration_labels,test_alphas_0,test_alphas_1,randomized=False):\n",
    "    \"\"\"\n",
    "    Mondrian Inductive Conformal Predictor\n",
    "    Parameters:\n",
    "    calibration_alphas: 1d array of Nonconformity Measures for the calibration examples\n",
    "    calibration_labels: 1d array of labels for the calibration examples - ideally 0/1 or -1/+1,\n",
    "                        but negative/positive values also accepted\n",
    "    test_alpha_0: 1d array of NCMs for the test examples, assuming 0 as label\n",
    "    test_alpha_1: 1d array of NCMs for the test examples, assuming 1 as label\n",
    "    Returns:\n",
    "    p0,p1 : pair of arrays containing the p-values for label 0 and label 1\n",
    "    \"\"\"\n",
    "    if not len(calibration_labels)==len(calibration_alphas):\n",
    "        raise ValueError(\"calibration_labels and calibration alphas must have the same size\")\n",
    "    \n",
    "    if not len(np.atleast_1d(test_alphas_0))==len(np.atleast_1d(test_alphas_1)):\n",
    "        raise ValueError(\"test_alphas_0 and test_alphas_1 must have the same size\")\n",
    "    \n",
    "    p_0 = p_values(calibration_alphas[calibration_labels<=0],\n",
    "                   test_alphas_0,\n",
    "                   randomized)\n",
    "    p_1 = p_values(calibration_alphas[calibration_labels>0],\n",
    "                   test_alphas_1,\n",
    "                   randomized)\n",
    "    return p_0,p_1\n",
    "\n",
    "# function to predict label from p0 and p1\n",
    "def cp_label_predictor(p0, p1, eps):\n",
    "    # Active: p1 > ϵ and p0 ≤ ϵ\n",
    "    # Inactive: p0 > ϵ and p1 ≤ ϵ\n",
    "    # Uncertain (Both): p1 > ϵ and p0 > ϵ\n",
    "    # Empty (None): p1 ≤ ϵ and p0 ≤ ϵ\n",
    "    if p1 > eps and p0 <= eps:\n",
    "        return 1\n",
    "    elif p0 > eps and p1 <= eps:\n",
    "        return 0\n",
    "    elif p0 > eps and p1 > eps:\n",
    "        return 'uncertain both'\n",
    "    elif p0 <= eps and p1 <= eps:\n",
    "        # return 'empty'\n",
    "        # it should actually return 'empty', but to avoid a confusion for people\n",
    "        return 'uncertain none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG \n",
    "\n",
    "eps = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_preds = '../predictions/preds/pred_cpmodel_step2_inference_allcmpds-class.npy'\n",
    "preds = np.load(path_preds,allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../analysis/cp/labels_fva_fit_dict.json') as fp:\n",
    "    labels_fva_fit_dict = json.load(fp)\n",
    "with open('../analysis/cp/ncms_fva_fit_dict.json') as fp:\n",
    "    ncms_fva_fit_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(np.unique(preds.nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indxs = []\n",
    "n_active_preds = []\n",
    "n_inactive_preds = []\n",
    "n_uncertain_preds = []\n",
    "cp_values = {}\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    ncms_fva_col = np.array(ncms_fva_fit_dict[str(col)])\n",
    "    labels_fva_col = np.array(labels_fva_fit_dict[str(col)])\n",
    "    \n",
    "    preds_all_col = preds[:,col].data\n",
    "    \n",
    "    ncms_all_0 = prob_ncm(preds_all_col, np.repeat(0.,len(preds_all_col)))\n",
    "    ncms_all_1 = prob_ncm(preds_all_col, np.repeat(1.,len(preds_all_col)))\n",
    "    \n",
    "    p0, p1 = micp(ncms_fva_col,labels_fva_col,ncms_all_0,ncms_all_1,randomized=False)\n",
    "    cp_all = [cp_label_predictor(pe0, pe1, eps) for pe0, pe1 in zip(p0,p1)]\n",
    "\n",
    "    cp_values[col] = cp_all\n",
    "    \n",
    "    indxs.append(col)\n",
    "    n_active_preds.append(np.array([e==1 for e in cp_values[col]]).sum())\n",
    "    n_inactive_preds.append(np.array([e==0 for e in cp_values[col]]).sum())\n",
    "    n_uncertain_preds.append(np.array([e=='uncertain both' for e in cp_values[col]]).sum())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame({\n",
    "    'n_active_pred':n_active_preds\n",
    "    ,'n_inactive_pred':n_inactive_preds\n",
    "    ,'n_uncertain_pred':n_uncertain_preds\n",
    "    ,'col_indx':indxs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_for_aux = df_stats.query('n_active_pred>0 and n_inactive_pred>0')['col_indx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# janssen-specific\n",
    "\n",
    "##path = '../data/image_features/compound_map_phase2.txt'\n",
    "##compound_map = pd.read_csv(path).sort_values(by='mtx_row_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compound_map['compound_id'] = np.where(compound_map['COMPOUND_NR'].astype(str).str.contains('VX-'), compound_map['COMPOUND_NR'], compound_map['JN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arrs = []\n",
    "for task in tqdm(tasks_for_aux): \n",
    "    arrs.append(pd.DataFrame({\n",
    "            'standard_value':cp_values[task]\n",
    "            ,'input_compound_id':compound_map['compound_id']\n",
    "            ,'standard_qualifier':'='\n",
    "            ,'input_assay_id':task\n",
    "        }).query('standard_value == 0 or standard_value == 1'))\n",
    "\n",
    "arr = pd.concat(arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.to_csv('../data/aux_data/pre/T1_image_pseudolabel_aux_nolabels.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
