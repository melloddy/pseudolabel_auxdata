{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, lil_matrix, load_npz, save_npz, hstack\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = '/projects/melloddy/data/y2run_final/data_prep/y2_ext/y2_ext_noaux/matrices/cls/cls_T10_y.npz'\n",
    "y = load_npz(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_output_baseline_w_aux = '../aux_data_preperation/baseline_plus_aux_data/'\n",
    "path = os.path.join(tuner_output_baseline_w_aux, 'matrices/cls/cls_T10_y.npz')\n",
    "y_aux = load_npz(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse_main_fold0 = lil_matrix(y_aux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the y-sparse matrix for inference \n",
    "# Main tasks + fold 0 to limit the amount of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(tuner_output_baseline_w_aux, 'matrices/cls/cls_T11_fold_vector.npy')\n",
    "folds = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(tuner_output_baseline_w_aux, 'results_tmp/classification/T8c.csv')\n",
    "t8c = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../analysis/cp/summary_eps_0.05_mgd_cp.csv'\n",
    "df_cp_mgd = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching = pd.merge(\n",
    "    df_cp_mgd\n",
    "    ,t8c\n",
    "    ,on=['input_assay_id','threshold']\n",
    "    ,how='inner'\n",
    "    ,suffixes=('_image','_baselineaux')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49    1710.0\n",
       "50    1898.0\n",
       "51    2941.0\n",
       "52    2942.0\n",
       "53    2944.0\n",
       "Name: cont_classification_task_id, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "49    1710.0\n",
       "50    1898.0\n",
       "51    2941.0\n",
       "52    2942.0\n",
       "53    2944.0\n",
       "Name: cont_classification_task_id_baseline, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# main tasks \n",
    "# mind the difference between these two !\n",
    "# cont_classification_task_id is the baseline + aux model \n",
    "display(df_matching.query('validity_0 >= 0').query('validity_1 >= 0')['cont_classification_task_id'].tail())\n",
    "display(df_matching.query('validity_0 >= 0').query('validity_1 >= 0')['cont_classification_task_id_baseline'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matching.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './files/mapping/baseline_image_model_baselineaux_task_mapping.csv'\n",
    "df_matching.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [0\n",
    "       ,0.2\n",
    "       ,0.4\n",
    "       ,0.5\n",
    "       ,0.6\n",
    "       ,0.7\n",
    "       ,0.8\n",
    "       ,0.9\n",
    "       ,0.95\n",
    "       ,0.99\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 138.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "47\n",
      "28\n",
      "18\n",
      "10\n",
      "6\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i,l1 in tqdm(enumerate(lst)):\n",
    "    l2 = l1\n",
    "    print(df_matching.query('validity_0 > @l1').query('validity_1 > @l2')['cont_classification_task_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:04,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:06,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:07,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:08,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:09,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:09,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:10,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:10,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# new approach : for inference, only consider the main tasks that correspond to aux tasks meeting the criteria \n",
    "# instead of one general sparse y matrix \n",
    "\n",
    "base_path = '../aux_data_preperation/baseline_plus_aux_data/matrices/cls'\n",
    "\n",
    "for i,l1 in tqdm(enumerate(lst)):\n",
    "    y_sparse_main_fold0 = lil_matrix(y_aux.shape)\n",
    "    print(l1)\n",
    "    l2 = l1\n",
    "    #for j,l2 in enumerate(lst): \n",
    "    file_core = 'ppv{}_npv{}'.format(l1,l2).replace('.','_')\n",
    "    col_idxs = set(df_matching.query('validity_0 > @l1').query('validity_1 > @l2')['cont_classification_task_id'])\n",
    "    for col in col_idxs :\n",
    "        y_sparse_main_fold0[folds == 0,col] = 1\n",
    "    path = os.path.join(base_path, 'y_sparse_main_tasks_fold0_{}'.format(file_core))\n",
    "    save_npz(path,csr_matrix(y_sparse_main_fold0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mellody Tuner",
   "language": "python",
   "name": "melloddy_tuner_regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
