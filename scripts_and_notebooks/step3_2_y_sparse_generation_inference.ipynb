{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, lil_matrix, load_npz, save_npz, hstack, coo_matrix\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_output_baseline_w_aux = '../04_aux_data_preperation/baseline_plus_aux_data/'\n",
    "\n",
    "path = os.path.join(tuner_output_baseline_w_aux, 'matrices/cls/cls_T10_y.npz')\n",
    "y_aux = load_npz(path)\n",
    "y_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse_main_fold0 = lil_matrix(y_aux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the y-sparse matrix for inference \n",
    "# Main tasks + fold 0 to limit the amount of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(tuner_output_baseline_w_aux, 'matrices/cls/cls_T11_fold_vector.npy')\n",
    "folds = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './files/mapping/baseline_image_model_baselineaux_task_mapping.csv'\n",
    "df_matching = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching[['cont_classification_task_id', 'cont_classification_task_id_image', 'cont_classification_task_id_baseline', 'baseline_compliant_input_assay_id_image']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main tasks \n",
    "# mind the difference between these two !\n",
    "# cont_classification_task_id is the baseline + aux model \n",
    "display(df_matching.query('validity_0 >= 0').query('validity_1 >= 0')['cont_classification_task_id'].tail())\n",
    "display(df_matching.query('validity_0 >= 0').query('validity_1 >= 0')['cont_classification_task_id_baseline'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [0\n",
    "       ,0.2\n",
    "       ,0.4\n",
    "       ,0.5\n",
    "       ,0.6\n",
    "       ,0.7\n",
    "       ,0.8\n",
    "       ,0.9\n",
    "       ,0.95\n",
    "       ,0.99\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l1 in tqdm(enumerate(lst)):\n",
    "    l2 = l1\n",
    "    print(df_matching.query('validity_0 > @l1').query('validity_1 > @l2')['cont_classification_task_id_baseline'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../04_aux_data_preperation/baseline_plus_aux_data/matrices/cls/fold_0'\n",
    "os.makedirs(base_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new approach : for inference, only consider the main tasks that correspond to aux tasks meeting the criteria \n",
    "# instead of one general sparse y matrix \n",
    "\n",
    "\n",
    "for i,l1 in tqdm(enumerate(lst)):\n",
    "    y_sparse_main_fold0 = lil_matrix(y_aux.shape)\n",
    "    l2 = l1\n",
    "    #for j,l2 in enumerate(lst): \n",
    "    file_core = 'ppv{}_npv{}'.format(l1,l2).replace('.','_')\n",
    "    col_idxs = set(df_matching.query('validity_0 > @l1').query('validity_1 > @l2')['cont_classification_task_id_baseline'].dropna())\n",
    "    for col in col_idxs :\n",
    "        y_sparse_main_fold0[folds == 0,col] = 1\n",
    "    path = os.path.join(base_path, 'y_sparse_main_tasks_fold0_{}'.format(file_core))\n",
    "    save_npz(path,csr_matrix(y_sparse_main_fold0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sparse_main_fold0 = lil_matrix(y_aux.shape)\n",
    "\n",
    "col_idxs = set(df_matching['cont_classification_task_id_baseline'])\n",
    "for col in col_idxs :\n",
    "    y_sparse_main_fold0[folds == 0,col] = 1\n",
    "path = os.path.join(base_path, 'y_sparse_main_tasks_fold0_baseline.npz')\n",
    "save_npz(path,csr_matrix(y_sparse_main_fold0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mellody Tuner",
   "language": "python",
   "name": "melloddy_tuner_regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
