{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, load_npz, save_npz, coo_matrix\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm \n",
    "import os \n",
    "import json \n",
    "import types \n",
    "import glob \n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsechem import load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvs = ['0'\n",
    "       ,'0_2'\n",
    "       ,'0_4'\n",
    "       ,'0_5'\n",
    "       ,'0_6'\n",
    "       ,'0_7'\n",
    "       ,'0_8'\n",
    "       ,'0_9'\n",
    "       ,'0_95'\n",
    "       ,'0_99'\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = './aux_data_preperation/baseline_plus_aux_data/'\n",
    "modelpath = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(datapath, 'results_tmp/classification/T8c.csv')\n",
    "t8c = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [4000,6000,8000]\n",
    "recs_baseline = []\n",
    "\n",
    "for size in sizes : \n",
    "    path = modelpath + '/aux_data_training/baseline_{}/models/classification_baseline.json'.format(size)\n",
    "    perf_baseline_aucroc = load_results(path)['validation']['classification_agg']['roc_auc_score']\n",
    "    perf_baseline_aucpr = load_results(path)['validation']['classification_agg']['auc_pr']\n",
    "    rec_baseline = pd.DataFrame({\n",
    "                'AUC ROC':[perf_baseline_aucroc]\n",
    "                ,'AUC PR':[perf_baseline_aucpr]\n",
    "                ,'size':[size]\n",
    "    })\n",
    "    recs_baseline.append(rec_baseline)\n",
    "    \n",
    "out_baseline = pd.concat(recs_baseline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_baselines = out_baseline.sort_values(by='AUC PR').iloc[-1]\n",
    "ser_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(glob.glob('./aux_data_training/ppv_npv_scan_{}_{}/*'.format(size,weight))):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sizes = [4000,4000,4000,6000,8000]\n",
    "weights = ['0_1','0_02','0_3','0_1','0_1']\n",
    "\n",
    "p_roc = []\n",
    "p_pr = []\n",
    "p_spr = []\n",
    "prim_perf = {}\n",
    "prim_perf_baseline = {}\n",
    "\n",
    "recs = []\n",
    "\n",
    "    \n",
    "perf_roc = 0 \n",
    "perf_pr = 0\n",
    "perf_spr = 0\n",
    "\n",
    "for i,size in enumerate(sizes) : \n",
    "    \n",
    "    weight = weights[i]\n",
    "    \n",
    "    for d in tqdm(glob.glob('./aux_data_training/ppv_npv_scan_{}_{}/*'.format(size,weight))): \n",
    "        path = os.path.join(d,'models','classification_baseline_w_aux.json')\n",
    "        res = load_results(path)['validation']['classification_agg']\n",
    "\n",
    "        thr = str(d).split('npv')[-1]\n",
    "\n",
    "        perf_roc = res['roc_auc_score']       \n",
    "        perf_pr = res['auc_pr']\n",
    "\n",
    "        rec = pd.DataFrame({\n",
    "                    'AUC ROC':[perf_roc]\n",
    "                    ,'AUC PR':[perf_pr]\n",
    "                    ,'quality_threshold':[thr]\n",
    "                    ,'weight':[weight]\n",
    "                    ,'size':[size]\n",
    "        })\n",
    "\n",
    "        recs.append(rec)\n",
    "\n",
    "        \n",
    "        \n",
    "out = pd.concat(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_res = out.groupby(['quality_threshold','weight','size']).agg([np.mean, np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'AUC ROC'\n",
    "\n",
    "df_res_4000_01 = df_res.query('weight == \"0_1\" and size==4000')\n",
    "df_res_4000_03 = df_res.query('weight == \"0_3\" and size==4000')\n",
    "df_res_4000_002 = df_res.query('weight == \"0_02\" and size==4000')\n",
    "df_res_6000_01 = df_res.query('weight == \"0_1\" and size==6000')\n",
    "df_res_8000_01 = df_res.query('weight == \"0_1\" and size==8000')\n",
    "\n",
    "\n",
    "_ = plt.plot(df_res_4000_01[metric]['mean'].values\n",
    "            ,c='navy'\n",
    "            ,ls='--')\n",
    "\n",
    "_ = plt.plot(df_res_4000_03[metric]['mean'].values\n",
    "            #,c='navy'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_4000_002[metric]['mean'].values\n",
    "            #,c='navy'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_6000_01[metric]['mean'].values\n",
    "            #,c='navy'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_8000_01[metric]['mean'].values\n",
    "            #,c='navy'\n",
    "            ,ls='--')\n",
    "\n",
    "plt.fill_between(\n",
    "    list(range(len(pvs)))\n",
    "    , df_res_4000_01[metric].amin.values\n",
    "    , df_res_4000_01[metric].amax.values \n",
    "    ,color='lightblue'\n",
    ")\n",
    "_ = plt.xticks(range(len(pvs)),pvs)\n",
    "plt.grid(axis='y'\n",
    "        ,ls='--'\n",
    "        )\n",
    "\n",
    "plt.plot(range(len(pvs)),np.repeat(ser_baselines[metric],repeats=len(pvs)),c='red')\n",
    "\n",
    "_ = plt.legend(\n",
    "    [\n",
    "        'layer size x1, weight 0.1'\n",
    "        ,'layer size x1, weight 0.3'\n",
    "        ,'layer size x1, weight 0.02'\n",
    "        ,'layer size x1.5, weight 0.1'\n",
    "        ,'layer size x2, weight 0.1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'AUC ROC'\n",
    "\n",
    "df_res_4000_01 = df_res.query('weight == \"0_1\" and size==4000')\n",
    "df_res_4000_03 = df_res.query('weight == \"0_3\" and size==4000')\n",
    "df_res_4000_002 = df_res.query('weight == \"0_02\" and size==4000')\n",
    "df_res_6000_01 = df_res.query('weight == \"0_1\" and size==6000')\n",
    "df_res_8000_01 = df_res.query('weight == \"0_1\" and size==8000')\n",
    "\n",
    "\n",
    "_ = plt.plot(df_res_4000_01[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='blue'\n",
    "            ,ls='--')\n",
    "\n",
    "_ = plt.plot(df_res_4000_03[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='green'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_4000_002[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='gray'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_6000_01[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='orange'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_8000_01[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='brown'\n",
    "            ,ls='--')\n",
    "\n",
    "plt.fill_between(\n",
    "    list(range(len(pvs)))\n",
    "    , df_res_4000_01[metric].amin.values-ser_baselines[metric]\n",
    "    , df_res_4000_01[metric].amax.values-ser_baselines[metric]\n",
    "    ,color='lightblue'\n",
    ")\n",
    "_ = plt.xticks(range(len(pvs)),pvs)\n",
    "plt.grid(axis='y'\n",
    "        ,ls='--')\n",
    "\n",
    "plt.plot(range(len(pvs)),np.repeat(0,repeats=len(pvs)), c='red')\n",
    "\n",
    "_ = plt.legend(\n",
    "    [\n",
    "        'layer size x1, weight 0.1'\n",
    "        ,'layer size x1, weight 0.3'\n",
    "        ,'layer size x1, weight 0.02'\n",
    "        ,'layer size x1.5, weight 0.1'\n",
    "        ,'layer size x2, weight 0.1'\n",
    "        ,'baseline'\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.ylim([-.004,.004])\n",
    "\n",
    "_ = plt.ylabel(metric)\n",
    "_ = plt.xlabel('task quality criterium (NPV and PPV > threshold)\\nused for task selection\\n(training)')\n",
    "\n",
    "plt.savefig('./results/{}_reruns.png'.format(metric)\n",
    "                      ,bbox_inches='tight'\n",
    "            ,pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'AUC PR'\n",
    "\n",
    "df_res_4000_01 = df_res.query('weight == \"0_1\" and size==4000')\n",
    "df_res_4000_03 = df_res.query('weight == \"0_3\" and size==4000')\n",
    "df_res_4000_002 = df_res.query('weight == \"0_02\" and size==4000')\n",
    "df_res_6000_01 = df_res.query('weight == \"0_1\" and size==6000')\n",
    "df_res_8000_01 = df_res.query('weight == \"0_1\" and size==8000')\n",
    "\n",
    "\n",
    "_ = plt.plot(df_res_4000_01[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='blue'\n",
    "            ,ls='--')\n",
    "\n",
    "_ = plt.plot(df_res_4000_03[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='green'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_4000_002[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='gray'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_6000_01[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='orange'\n",
    "            ,ls='--')\n",
    "_ = plt.plot(df_res_8000_01[metric]['mean'].values-ser_baselines[metric]\n",
    "            ,c='brown'\n",
    "            ,ls='--')\n",
    "\n",
    "\n",
    "plt.fill_between(\n",
    "    list(range(len(pvs)))\n",
    "    , df_res_4000_01[metric].amin.values-ser_baselines[metric]\n",
    "    , df_res_4000_01[metric].amax.values-ser_baselines[metric]\n",
    "    ,color='lightblue'\n",
    ")\n",
    "_ = plt.xticks(range(len(pvs)),pvs)\n",
    "plt.grid(axis='y'\n",
    "        ,ls='--')\n",
    "\n",
    "plt.plot(range(len(pvs)),np.repeat(0,repeats=len(pvs)), c='red')\n",
    "\n",
    "_ = plt.legend(\n",
    "    [\n",
    "        'layer size x1, weight 0.1'\n",
    "        ,'layer size x1, weight 0.3'\n",
    "        ,'layer size x1, weight 0.02'\n",
    "        ,'layer size x1.5, weight 0.1'\n",
    "        ,'layer size x2, weight 0.1'\n",
    "        ,'baseline'\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.ylim([-.004,.004])\n",
    "\n",
    "_ = plt.ylabel(metric)\n",
    "_ = plt.xlabel('task quality criterium (NPV and PPV > threshold)\\nused for task selection\\n(training)')\n",
    "\n",
    "plt.savefig('./results/{}_reruns.png'.format(metric)\n",
    "                      ,bbox_inches='tight'\n",
    "            ,pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-melloddy_pipeline]",
   "language": "python",
   "name": "conda-env-.conda-melloddy_pipeline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
