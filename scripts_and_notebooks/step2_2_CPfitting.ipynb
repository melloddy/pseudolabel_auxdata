{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import load_npz, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_ncm(scores, labels):\n",
    "    \"\"\"\n",
    "    Converts Neural Network scores into Nonconformity Measures for CP.\n",
    "    Assumes that scores are directly related to the probability of being active\n",
    "    \"\"\"\n",
    "    return np.where( labels > 0, -scores, scores )\n",
    "\n",
    "### p-Values calculation\n",
    "def p_values(calibration_alphas, test_alphas, randomized=False):\n",
    "    sorted_cal_alphas = sorted(calibration_alphas)\n",
    "    if randomized:\n",
    "        # for each test alpha, tieBreaker is the (number of calibration alphas with the same value)*(uniform RV between 0 and 1)\n",
    "        tie_counts = np.searchsorted(sorted_cal_alphas,test_alphas,side='right')-np.searchsorted(sorted_cal_alphas,test_alphas)\n",
    "        tie_breaker = np.random.uniform(size=len(np.atleast_1d(test_alphas)))*tie_counts\n",
    "        return  (len(calibration_alphas)-(np.searchsorted(sorted_cal_alphas,test_alphas,side='right')-tie_breaker)+1)/(len(calibration_alphas)+1)\n",
    "    else:\n",
    "        return  (len(calibration_alphas)-np.searchsorted(sorted_cal_alphas,test_alphas)+1)/(len(calibration_alphas)+1)\n",
    "\n",
    "# Mondrian Inductive Conformal Predictor\n",
    "def micp(calibration_alphas,calibration_labels,test_alphas_0,test_alphas_1,randomized=False):\n",
    "    \"\"\"\n",
    "    Mondrian Inductive Conformal Predictor\n",
    "    Parameters:\n",
    "    calibration_alphas: 1d array of Nonconformity Measures for the calibration examples\n",
    "    calibration_labels: 1d array of labels for the calibration examples - ideally 0/1 or -1/+1,\n",
    "                        but negative/positive values also accepted\n",
    "    test_alpha_0: 1d array of NCMs for the test examples, assuming 0 as label\n",
    "    test_alpha_1: 1d array of NCMs for the test examples, assuming 1 as label\n",
    "    Returns:\n",
    "    p0,p1 : pair of arrays containing the p-values for label 0 and label 1\n",
    "    \"\"\"\n",
    "    if not len(calibration_labels)==len(calibration_alphas):\n",
    "        raise ValueError(\"calibration_labels and calibration alphas must have the same size\")\n",
    "    \n",
    "    if not len(np.atleast_1d(test_alphas_0))==len(np.atleast_1d(test_alphas_1)):\n",
    "        raise ValueError(\"test_alphas_0 and test_alphas_1 must have the same size\")\n",
    "    \n",
    "    p_0 = p_values(calibration_alphas[calibration_labels<=0],\n",
    "                   test_alphas_0,\n",
    "                   randomized)\n",
    "    p_1 = p_values(calibration_alphas[calibration_labels>0],\n",
    "                   test_alphas_1,\n",
    "                   randomized)\n",
    "    return p_0,p_1\n",
    "\n",
    "# function to predict label from p0 and p1\n",
    "def cp_label_predictor(p0, p1, eps):\n",
    "    # Active: p1 > ϵ and p0 ≤ ϵ\n",
    "    # Inactive: p0 > ϵ and p1 ≤ ϵ\n",
    "    # Uncertain (Both): p1 > ϵ and p0 > ϵ\n",
    "    # Empty (None): p1 ≤ ϵ and p0 ≤ ϵ\n",
    "    if p1 > eps and p0 <= eps:\n",
    "        return 1\n",
    "    elif p0 > eps and p1 <= eps:\n",
    "        return 0\n",
    "    elif p0 > eps and p1 > eps:\n",
    "        return 'uncertain both'\n",
    "    elif p0 <= eps and p1 <= eps:\n",
    "        # return 'empty'\n",
    "        # it should actually return 'empty', but to avoid a confusion for people\n",
    "        return 'uncertain none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG \n",
    "\n",
    "eps = 0.05\n",
    "fold_va = 2\n",
    "path = '../../data/Mellody_tuner/images/output_images/pseudolabels'\n",
    "fva_preds = '../../Classification_no_aux/predictions/01_cls/cls/pred_images-class.npy'\n",
    "path_folds = path+'/matrices/cls/cls_T11_fold_vector.npy'\n",
    "path_labels = path+'/matrices/cls/cls_T10_y.npz'\n",
    "path_sn = path+'/results_tmp/folding/T2_folds.csv'\n",
    "path_t5 = path+'/mapping_table/T5.csv' \n",
    "path_t6_cont = path+'/results/T10c_cont.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = np.load(path_folds,allow_pickle=True)\n",
    "labels = load_npz(path_labels).tocsr()\n",
    "preds_fva = np.load(fva_preds,allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10077, 285)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = pd.read_csv(path_sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10077x285 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 184789 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_fva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sn_smiles\n",
       "c1ccc2[nH]ccc2c1                          70\n",
       "O=C1NCCCOCc2ccccc2-c2c1[nH]c1ccccc21      52\n",
       "O=S1(=O)NCCCOc2cc(C#Cc3ccccc3)ccc21       35\n",
       "c1ccc2ccccc2c1                            25\n",
       "O=S(=O)(Nc1ccccc1)c1ccccc1                21\n",
       "                                          ..\n",
       "O=C1NC(=O)C(=Cc2c[nH]c3ccccc23)C(=O)N1     1\n",
       "O=C1N=CC(C(=O)OCc2ccc3c(c2)OCO3)CN1        1\n",
       "O=C1N=CC(C(=O)OC2CCCCC2)C(c2ccccc2)N1      1\n",
       "O=C1N=CC(=Cc2ccccc2)S1                     1\n",
       "c1nonc1-c1n[nH]c(-c2cnon2)n1               1\n",
       "Name: input_compound_id, Length: 1209, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_fold2 = sn.query('fold_id == 2')\n",
    "sn_scaffolds = sn_fold2.groupby(by='sn_smiles').count()['input_compound_id'].sort_values(ascending=False)\n",
    "sn_scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sn_scaffolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1208,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile([0,1],reps=len(sn_scaffolds)//2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(np.tile([0,1],reps=len(sn_scaffolds)//2),np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_map = sn_scaffolds.reset_index().drop(columns='input_compound_id')\n",
    "sn_map['fold_split'] = np.append(np.tile([0,1],reps=len(sn_scaffolds)//2),np.array([1])) # ensuring similar size of both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_mgd = pd.merge(\n",
    "    sn_fold2\n",
    "    ,sn_map\n",
    "    ,how='inner'\n",
    "    ,on='sn_smiles'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sn_mgd) == len(sn_fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sn_mgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to the cdi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = pd.read_csv(path_t5)\n",
    "t6_cont = pd.read_csv(path_t6_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mgd = pd.merge(\n",
    "        pd.merge(\n",
    "            t5\n",
    "            ,t6_cont\n",
    "            ,how='inner'\n",
    "            ,on='descriptor_vector_id'\n",
    "        ), \n",
    "        sn_mgd\n",
    "        ,how='inner'\n",
    "        ,on='input_compound_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37584, 24)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mgd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['input_compound_id', 'fold_id_x', 'descriptor_vector_id',\n",
       "       'classification_task_id', 'fold_id_y', 'input_assay_id',\n",
       "       'standard_qualifier', 'standard_value', 'threshold', 'class_label',\n",
       "       'is_active', 'is_inactive', 'cont_classification_task_id',\n",
       "       'cont_descriptor_vector_id', 'smiles', 'canonical_smiles', 'success',\n",
       "       'error_message', 'fp_feat', 'fp_val', 'murcko_smiles', 'sn_smiles',\n",
       "       'fold_id', 'fold_split'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mgd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half of fold2 will be used to fit the CP, \n",
    "# half of fold2 will be used to evaluate the CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 11: 11,\n",
       " 12: 12,\n",
       " 13: 13,\n",
       " 14: 14,\n",
       " 15: 15,\n",
       " 16: 16,\n",
       " 17: 17,\n",
       " 18: 18,\n",
       " 19: 19,\n",
       " 20: 20,\n",
       " 21: 21,\n",
       " 22: 22,\n",
       " 23: 23,\n",
       " 24: 24,\n",
       " 25: 25,\n",
       " 26: 26,\n",
       " 27: 27,\n",
       " 28: 28,\n",
       " 29: 29,\n",
       " 30: 30,\n",
       " 31: 31,\n",
       " 32: 32,\n",
       " 33: 33,\n",
       " 34: 34,\n",
       " 35: 35,\n",
       " 36: 36,\n",
       " 37: 37,\n",
       " 38: 38,\n",
       " 39: 39,\n",
       " 40: 40,\n",
       " 41: 41,\n",
       " 42: 42,\n",
       " 43: 43,\n",
       " 44: 44,\n",
       " 45: 45,\n",
       " 46: 46,\n",
       " 47: 47,\n",
       " 48: 48,\n",
       " 49: 49,\n",
       " 50: 50,\n",
       " 51: 51,\n",
       " 52: 52,\n",
       " 53: 53,\n",
       " 54: 54,\n",
       " 55: 55,\n",
       " 56: 56,\n",
       " 57: 57,\n",
       " 58: 58,\n",
       " 59: 59,\n",
       " 60: 60,\n",
       " 61: 61,\n",
       " 62: 62,\n",
       " 63: 63,\n",
       " 64: 64,\n",
       " 65: 65,\n",
       " 66: 66,\n",
       " 67: 67,\n",
       " 68: 68,\n",
       " 69: 69,\n",
       " 70: 70,\n",
       " 71: 71,\n",
       " 72: 72,\n",
       " 73: 73,\n",
       " 74: 74,\n",
       " 75: 75,\n",
       " 76: 76,\n",
       " 77: 77,\n",
       " 78: 78,\n",
       " 79: 79,\n",
       " 80: 80,\n",
       " 81: 81,\n",
       " 82: 82,\n",
       " 83: 83,\n",
       " 84: 84,\n",
       " 85: 85,\n",
       " 86: 86,\n",
       " 87: 87,\n",
       " 88: 88,\n",
       " 89: 89,\n",
       " 90: 90,\n",
       " 91: 91,\n",
       " 92: 92,\n",
       " 93: 93,\n",
       " 94: 94,\n",
       " 95: 95,\n",
       " 96: 96,\n",
       " 97: 97,\n",
       " 98: 98,\n",
       " 99: 99,\n",
       " 100: 100,\n",
       " 101: 101,\n",
       " 102: 102,\n",
       " 103: 103,\n",
       " 104: 104,\n",
       " 105: 105,\n",
       " 106: 106,\n",
       " 107: 107,\n",
       " 108: 108,\n",
       " 109: 109,\n",
       " 110: 110,\n",
       " 111: 111,\n",
       " 112: 112,\n",
       " 113: 113,\n",
       " 114: 114,\n",
       " 115: 115,\n",
       " 116: 116,\n",
       " 117: 117,\n",
       " 118: 118,\n",
       " 119: 119,\n",
       " 120: 120,\n",
       " 121: 121,\n",
       " 122: 122,\n",
       " 123: 123,\n",
       " 124: 124,\n",
       " 125: 125,\n",
       " 126: 126,\n",
       " 127: 127,\n",
       " 128: 128,\n",
       " 129: 129,\n",
       " 130: 130,\n",
       " 131: 131,\n",
       " 132: 132,\n",
       " 133: 133,\n",
       " 134: 134,\n",
       " 135: 135,\n",
       " 136: 136,\n",
       " 137: 137,\n",
       " 138: 138,\n",
       " 139: 139,\n",
       " 140: 140,\n",
       " 141: 141,\n",
       " 142: 142,\n",
       " 143: 143,\n",
       " 144: 144,\n",
       " 145: 145,\n",
       " 146: 146,\n",
       " 147: 147,\n",
       " 148: 148,\n",
       " 149: 149,\n",
       " 150: 150,\n",
       " 151: 151,\n",
       " 152: 152,\n",
       " 153: 153,\n",
       " 154: 154,\n",
       " 155: 155,\n",
       " 156: 156,\n",
       " 157: 157,\n",
       " 158: 158,\n",
       " 159: 159,\n",
       " 160: 160,\n",
       " 161: 161,\n",
       " 162: 162,\n",
       " 163: 163,\n",
       " 164: 164,\n",
       " 165: 165,\n",
       " 166: 166,\n",
       " 167: 167,\n",
       " 168: 168,\n",
       " 169: 169,\n",
       " 170: 170,\n",
       " 171: 171,\n",
       " 172: 172,\n",
       " 173: 173,\n",
       " 174: 174,\n",
       " 175: 175,\n",
       " 176: 176,\n",
       " 177: 177,\n",
       " 178: 178,\n",
       " 179: 179,\n",
       " 180: 180,\n",
       " 181: 181,\n",
       " 182: 182,\n",
       " 183: 183,\n",
       " 184: 184,\n",
       " 185: 185,\n",
       " 186: 186,\n",
       " 187: 187,\n",
       " 188: 188,\n",
       " 189: 189,\n",
       " 190: 190,\n",
       " 191: 191,\n",
       " 192: 192,\n",
       " 193: 193,\n",
       " 194: 194,\n",
       " 195: 195,\n",
       " 196: 196,\n",
       " 197: 197,\n",
       " 198: 198,\n",
       " 199: 199,\n",
       " 200: 200,\n",
       " 201: 201,\n",
       " 202: 202,\n",
       " 203: 203,\n",
       " 204: 204,\n",
       " 205: 205,\n",
       " 206: 206,\n",
       " 207: 207,\n",
       " 208: 208,\n",
       " 209: 209,\n",
       " 210: 210,\n",
       " 211: 211,\n",
       " 212: 212,\n",
       " 213: 213,\n",
       " 214: 214,\n",
       " 215: 215,\n",
       " 216: 216,\n",
       " 217: 217,\n",
       " 218: 218,\n",
       " 219: 219,\n",
       " 220: 220,\n",
       " 221: 221,\n",
       " 222: 222,\n",
       " 223: 223,\n",
       " 224: 224,\n",
       " 225: 225,\n",
       " 226: 226,\n",
       " 227: 227,\n",
       " 228: 228,\n",
       " 229: 229,\n",
       " 230: 230,\n",
       " 231: 231,\n",
       " 232: 232,\n",
       " 233: 233,\n",
       " 234: 234,\n",
       " 235: 235,\n",
       " 236: 236,\n",
       " 237: 237,\n",
       " 238: 238,\n",
       " 239: 239,\n",
       " 240: 240,\n",
       " 241: 241,\n",
       " 242: 242,\n",
       " 243: 243,\n",
       " 244: 244,\n",
       " 245: 245,\n",
       " 246: 246,\n",
       " 247: 247,\n",
       " 248: 248,\n",
       " 249: 249,\n",
       " 250: 250,\n",
       " 251: 251,\n",
       " 252: 252,\n",
       " 253: 253,\n",
       " 254: 254,\n",
       " 255: 255,\n",
       " 256: 256,\n",
       " 257: 257,\n",
       " 258: 258,\n",
       " 259: 259,\n",
       " 260: 260,\n",
       " 261: 261,\n",
       " 262: 262,\n",
       " 263: 263,\n",
       " 264: 264,\n",
       " 265: 265,\n",
       " 266: 266,\n",
       " 267: 267,\n",
       " 268: 268,\n",
       " 269: 269,\n",
       " 270: 270,\n",
       " 271: 271,\n",
       " 272: 272,\n",
       " 273: 273,\n",
       " 274: 274,\n",
       " 275: 275,\n",
       " 276: 276,\n",
       " 277: 277,\n",
       " 278: 278,\n",
       " 279: 279,\n",
       " 280: 280,\n",
       " 281: 281,\n",
       " 282: 282,\n",
       " 283: 283,\n",
       " 284: 284,\n",
       " 285: 285,\n",
       " 286: 286,\n",
       " 287: 287,\n",
       " 288: 288,\n",
       " 289: 289,\n",
       " 290: 290,\n",
       " 291: 291,\n",
       " 292: 292,\n",
       " 293: 293,\n",
       " 294: 294,\n",
       " 295: 295,\n",
       " 296: 296,\n",
       " 297: 297,\n",
       " 298: 298,\n",
       " 299: 299,\n",
       " 300: 300,\n",
       " 301: 301,\n",
       " 302: 302,\n",
       " 303: 303,\n",
       " 304: 304,\n",
       " 305: 305,\n",
       " 306: 306,\n",
       " 307: 307,\n",
       " 308: 308,\n",
       " 309: 309,\n",
       " 310: 310,\n",
       " 311: 311,\n",
       " 312: 312,\n",
       " 313: 313,\n",
       " 314: 314,\n",
       " 315: 315,\n",
       " 316: 316,\n",
       " 317: 317,\n",
       " 318: 318,\n",
       " 319: 319,\n",
       " 320: 320,\n",
       " 321: 321,\n",
       " 322: 322,\n",
       " 323: 323,\n",
       " 324: 324,\n",
       " 325: 325,\n",
       " 326: 326,\n",
       " 327: 327,\n",
       " 328: 328,\n",
       " 329: 329,\n",
       " 330: 330,\n",
       " 331: 331,\n",
       " 332: 332,\n",
       " 333: 333,\n",
       " 334: 334,\n",
       " 335: 335,\n",
       " 336: 336,\n",
       " 337: 337,\n",
       " 338: 338,\n",
       " 339: 339,\n",
       " 340: 340,\n",
       " 341: 341,\n",
       " 342: 342,\n",
       " 343: 343,\n",
       " 344: 344,\n",
       " 345: 345,\n",
       " 346: 346,\n",
       " 347: 347,\n",
       " 348: 348,\n",
       " 349: 349,\n",
       " 350: 350,\n",
       " 351: 351,\n",
       " 352: 352,\n",
       " 353: 353,\n",
       " 354: 354,\n",
       " 355: 355,\n",
       " 356: 356,\n",
       " 357: 357,\n",
       " 358: 358,\n",
       " 359: 359,\n",
       " 360: 360,\n",
       " 361: 361,\n",
       " 362: 362,\n",
       " 363: 363,\n",
       " 364: 364,\n",
       " 365: 365,\n",
       " 366: 366,\n",
       " 367: 367,\n",
       " 368: 368,\n",
       " 369: 369,\n",
       " 370: 370,\n",
       " 371: 371,\n",
       " 372: 372,\n",
       " 373: 373,\n",
       " 374: 374,\n",
       " 375: 375,\n",
       " 376: 376,\n",
       " 377: 377,\n",
       " 378: 378,\n",
       " 379: 379,\n",
       " 380: 380,\n",
       " 381: 381,\n",
       " 382: 382,\n",
       " 383: 383,\n",
       " 384: 384,\n",
       " 385: 385,\n",
       " 386: 386,\n",
       " 387: 387,\n",
       " 388: 388,\n",
       " 389: 389,\n",
       " 390: 390,\n",
       " 391: 391,\n",
       " 392: 392,\n",
       " 393: 393,\n",
       " 394: 394,\n",
       " 395: 395,\n",
       " 396: 396,\n",
       " 397: 397,\n",
       " 398: 398,\n",
       " 399: 399,\n",
       " 400: 400,\n",
       " 401: 401,\n",
       " 402: 402,\n",
       " 403: 403,\n",
       " 404: 404,\n",
       " 405: 405,\n",
       " 406: 406,\n",
       " 407: 407,\n",
       " 408: 408,\n",
       " 409: 409,\n",
       " 410: 410,\n",
       " 411: 411,\n",
       " 412: 412,\n",
       " 413: 413,\n",
       " 414: 414,\n",
       " 415: 415,\n",
       " 416: 416,\n",
       " 417: 417,\n",
       " 418: 418,\n",
       " 419: 419,\n",
       " 420: 420,\n",
       " 421: 421,\n",
       " 422: 422,\n",
       " 423: 423,\n",
       " 424: 424,\n",
       " 425: 425,\n",
       " 426: 426,\n",
       " 427: 427,\n",
       " 428: 428,\n",
       " 429: 429,\n",
       " 430: 430,\n",
       " 431: 431,\n",
       " 432: 432,\n",
       " 433: 433,\n",
       " 434: 434,\n",
       " 435: 435,\n",
       " 436: 436,\n",
       " 437: 437,\n",
       " 438: 438,\n",
       " 439: 439,\n",
       " 440: 440,\n",
       " 441: 441,\n",
       " 442: 442,\n",
       " 443: 443,\n",
       " 444: 444,\n",
       " 445: 445,\n",
       " 446: 446,\n",
       " 447: 447,\n",
       " 448: 448,\n",
       " 449: 449,\n",
       " 450: 450,\n",
       " 451: 451,\n",
       " 452: 452,\n",
       " 453: 453,\n",
       " 454: 454,\n",
       " 455: 455,\n",
       " 456: 456,\n",
       " 457: 457,\n",
       " 458: 458,\n",
       " 459: 459,\n",
       " 460: 460,\n",
       " 461: 461,\n",
       " 462: 462,\n",
       " 463: 463,\n",
       " 464: 464,\n",
       " 465: 465,\n",
       " 466: 466,\n",
       " 467: 467,\n",
       " 468: 468,\n",
       " 469: 469,\n",
       " 470: 470,\n",
       " 471: 471,\n",
       " 472: 472,\n",
       " 473: 473,\n",
       " 474: 474,\n",
       " 475: 475,\n",
       " 476: 476,\n",
       " 477: 477,\n",
       " 478: 478,\n",
       " 479: 479,\n",
       " 480: 480,\n",
       " 481: 481,\n",
       " 482: 482,\n",
       " 483: 483,\n",
       " 484: 484,\n",
       " 485: 485,\n",
       " 486: 486,\n",
       " 487: 487,\n",
       " 488: 488,\n",
       " 489: 489,\n",
       " 490: 490,\n",
       " 491: 491,\n",
       " 492: 492,\n",
       " 493: 493,\n",
       " 494: 494,\n",
       " 495: 495,\n",
       " 496: 496,\n",
       " 497: 497,\n",
       " 498: 498,\n",
       " 499: 499,\n",
       " 500: 500,\n",
       " 501: 501,\n",
       " 502: 502,\n",
       " 503: 503,\n",
       " 504: 504,\n",
       " 505: 505,\n",
       " 506: 506,\n",
       " 507: 507,\n",
       " 508: 508,\n",
       " 509: 509,\n",
       " 510: 510,\n",
       " 511: 511,\n",
       " 512: 512,\n",
       " 513: 513,\n",
       " 514: 514,\n",
       " 515: 515,\n",
       " 516: 516,\n",
       " 517: 517,\n",
       " 518: 518,\n",
       " 519: 519,\n",
       " 520: 520,\n",
       " 521: 521,\n",
       " 522: 522,\n",
       " 523: 523,\n",
       " 524: 524,\n",
       " 525: 525,\n",
       " 526: 526,\n",
       " 527: 527,\n",
       " 528: 528,\n",
       " 529: 529,\n",
       " 530: 530,\n",
       " 531: 531,\n",
       " 532: 532,\n",
       " 533: 533,\n",
       " 534: 534,\n",
       " 535: 535,\n",
       " 536: 536,\n",
       " 537: 537,\n",
       " 538: 538,\n",
       " 539: 539,\n",
       " 540: 540,\n",
       " 541: 541,\n",
       " 542: 542,\n",
       " 543: 543,\n",
       " 544: 544,\n",
       " 545: 545,\n",
       " 546: 546,\n",
       " 547: 547,\n",
       " 548: 548,\n",
       " 549: 549,\n",
       " 550: 550,\n",
       " 551: 551,\n",
       " 552: 552,\n",
       " 553: 553,\n",
       " 554: 554,\n",
       " 555: 555,\n",
       " 556: 556,\n",
       " 557: 557,\n",
       " 558: 558,\n",
       " 559: 559,\n",
       " 560: 560,\n",
       " 561: 561,\n",
       " 562: 562,\n",
       " 563: 563,\n",
       " 564: 564,\n",
       " 565: 565,\n",
       " 566: 566,\n",
       " 567: 567,\n",
       " 568: 568,\n",
       " 569: 569,\n",
       " 570: 570,\n",
       " 571: 571,\n",
       " 572: 572,\n",
       " 573: 573,\n",
       " 574: 574,\n",
       " 575: 575,\n",
       " 576: 576,\n",
       " 577: 577,\n",
       " 578: 578,\n",
       " 579: 579,\n",
       " 580: 580,\n",
       " 581: 581,\n",
       " 582: 582,\n",
       " 583: 583,\n",
       " 584: 584,\n",
       " 585: 585,\n",
       " 586: 586,\n",
       " 587: 587,\n",
       " 588: 588,\n",
       " 589: 589,\n",
       " 590: 590,\n",
       " 591: 591,\n",
       " 592: 592,\n",
       " 593: 593,\n",
       " 594: 594,\n",
       " 595: 595,\n",
       " 596: 596,\n",
       " 597: 597,\n",
       " 598: 598,\n",
       " 599: 599,\n",
       " 600: 600,\n",
       " 601: 601,\n",
       " 602: 602,\n",
       " 603: 603,\n",
       " 604: 604,\n",
       " 605: 605,\n",
       " 606: 606,\n",
       " 607: 607,\n",
       " 608: 608,\n",
       " 609: 609,\n",
       " 610: 610,\n",
       " 611: 611,\n",
       " 612: 612,\n",
       " 613: 613,\n",
       " 614: 614,\n",
       " 615: 615,\n",
       " 616: 616,\n",
       " 617: 617,\n",
       " 618: 618,\n",
       " 619: 619,\n",
       " 620: 620,\n",
       " 621: 621,\n",
       " 622: 622,\n",
       " 623: 623,\n",
       " 624: 624,\n",
       " 625: 625,\n",
       " 626: 626,\n",
       " 627: 627,\n",
       " 628: 628,\n",
       " 629: 629,\n",
       " 630: 630,\n",
       " 631: 631,\n",
       " 632: 632,\n",
       " 633: 633,\n",
       " 634: 634,\n",
       " 635: 635,\n",
       " 636: 636,\n",
       " 637: 637,\n",
       " 638: 638,\n",
       " 639: 639,\n",
       " 640: 640,\n",
       " 641: 641,\n",
       " 642: 642,\n",
       " 643: 643,\n",
       " 644: 644,\n",
       " 645: 645,\n",
       " 646: 646,\n",
       " 647: 647,\n",
       " 648: 648,\n",
       " 649: 649,\n",
       " 650: 650,\n",
       " 651: 651,\n",
       " 652: 652,\n",
       " 653: 653,\n",
       " 654: 654,\n",
       " 655: 655,\n",
       " 656: 656,\n",
       " 657: 657,\n",
       " 658: 658,\n",
       " 659: 659,\n",
       " 660: 660,\n",
       " 661: 661,\n",
       " 662: 662,\n",
       " 663: 663,\n",
       " 664: 664,\n",
       " 665: 665,\n",
       " 666: 666,\n",
       " 667: 667,\n",
       " 668: 668,\n",
       " 669: 669,\n",
       " 670: 670,\n",
       " 671: 671,\n",
       " 672: 672,\n",
       " 673: 673,\n",
       " 674: 674,\n",
       " 675: 675,\n",
       " 676: 676,\n",
       " 677: 677,\n",
       " 678: 678,\n",
       " 679: 679,\n",
       " 680: 680,\n",
       " 681: 681,\n",
       " 682: 682,\n",
       " 683: 683,\n",
       " 684: 684,\n",
       " 685: 685,\n",
       " 686: 686,\n",
       " 687: 687,\n",
       " 688: 688,\n",
       " 689: 689,\n",
       " 690: 690,\n",
       " 691: 691,\n",
       " 692: 692,\n",
       " 693: 693,\n",
       " 694: 694,\n",
       " 695: 695,\n",
       " 696: 696,\n",
       " 697: 697,\n",
       " 698: 698,\n",
       " 699: 699,\n",
       " 700: 700,\n",
       " 701: 701,\n",
       " 702: 702,\n",
       " 703: 703,\n",
       " 704: 704,\n",
       " 705: 705,\n",
       " 706: 706,\n",
       " 707: 707,\n",
       " 708: 708,\n",
       " 709: 709,\n",
       " 710: 710,\n",
       " 711: 711,\n",
       " 712: 712,\n",
       " 713: 713,\n",
       " 714: 714,\n",
       " 715: 715,\n",
       " 716: 716,\n",
       " 717: 717,\n",
       " 718: 718,\n",
       " 719: 719,\n",
       " 720: 720,\n",
       " 721: 721,\n",
       " 722: 722,\n",
       " 723: 723,\n",
       " 724: 724,\n",
       " 725: 725,\n",
       " 726: 726,\n",
       " 727: 727,\n",
       " 728: 728,\n",
       " 729: 729,\n",
       " 730: 730,\n",
       " 731: 731,\n",
       " 732: 732,\n",
       " 733: 733,\n",
       " 734: 734,\n",
       " 735: 735,\n",
       " 736: 736,\n",
       " 737: 737,\n",
       " 738: 738,\n",
       " 739: 739,\n",
       " 740: 740,\n",
       " 741: 741,\n",
       " 742: 742,\n",
       " 743: 743,\n",
       " 744: 744,\n",
       " 745: 745,\n",
       " 746: 746,\n",
       " 747: 747,\n",
       " 748: 748,\n",
       " 749: 749,\n",
       " 750: 750,\n",
       " 751: 751,\n",
       " 752: 752,\n",
       " 753: 753,\n",
       " 754: 754,\n",
       " 755: 755,\n",
       " 756: 756,\n",
       " 757: 757,\n",
       " 758: 758,\n",
       " 759: 759,\n",
       " 760: 760,\n",
       " 761: 761,\n",
       " 762: 762,\n",
       " 763: 763,\n",
       " 764: 764,\n",
       " 765: 765,\n",
       " 766: 766,\n",
       " 767: 767,\n",
       " 768: 768,\n",
       " 769: 769,\n",
       " 770: 770,\n",
       " 771: 771,\n",
       " 772: 772,\n",
       " 773: 773,\n",
       " 774: 774,\n",
       " 775: 775,\n",
       " 776: 776,\n",
       " 777: 777,\n",
       " 778: 778,\n",
       " 779: 779,\n",
       " 780: 780,\n",
       " 781: 781,\n",
       " 782: 782,\n",
       " 783: 783,\n",
       " 784: 784,\n",
       " 785: 785,\n",
       " 786: 786,\n",
       " 787: 787,\n",
       " 788: 788,\n",
       " 789: 789,\n",
       " 790: 790,\n",
       " 791: 791,\n",
       " 792: 792,\n",
       " 793: 793,\n",
       " 794: 794,\n",
       " 795: 795,\n",
       " 796: 796,\n",
       " 797: 797,\n",
       " 798: 798,\n",
       " 799: 799,\n",
       " 800: 800,\n",
       " 801: 801,\n",
       " 802: 802,\n",
       " 803: 803,\n",
       " 804: 804,\n",
       " 805: 805,\n",
       " 806: 806,\n",
       " 807: 807,\n",
       " 808: 808,\n",
       " 809: 809,\n",
       " 810: 810,\n",
       " 811: 811,\n",
       " 812: 812,\n",
       " 813: 813,\n",
       " 814: 814,\n",
       " 815: 815,\n",
       " 816: 816,\n",
       " 817: 817,\n",
       " 818: 818,\n",
       " 819: 819,\n",
       " 820: 820,\n",
       " 821: 821,\n",
       " 822: 822,\n",
       " 823: 823,\n",
       " 824: 824,\n",
       " 825: 825,\n",
       " 826: 826,\n",
       " 827: 827,\n",
       " 828: 828,\n",
       " 829: 829,\n",
       " 830: 830,\n",
       " 831: 831,\n",
       " 832: 832,\n",
       " 833: 833,\n",
       " 834: 834,\n",
       " 835: 835,\n",
       " 836: 836,\n",
       " 837: 837,\n",
       " 838: 838,\n",
       " 839: 839,\n",
       " 840: 840,\n",
       " 841: 841,\n",
       " 842: 842,\n",
       " 843: 843,\n",
       " 844: 844,\n",
       " 845: 845,\n",
       " 846: 846,\n",
       " 847: 847,\n",
       " 848: 848,\n",
       " 849: 849,\n",
       " 850: 850,\n",
       " 851: 851,\n",
       " 852: 852,\n",
       " 853: 853,\n",
       " 854: 854,\n",
       " 855: 855,\n",
       " 856: 856,\n",
       " 857: 857,\n",
       " 858: 858,\n",
       " 859: 859,\n",
       " 860: 860,\n",
       " 861: 861,\n",
       " 862: 862,\n",
       " 863: 863,\n",
       " 864: 864,\n",
       " 865: 865,\n",
       " 866: 866,\n",
       " 867: 867,\n",
       " 868: 868,\n",
       " 869: 869,\n",
       " 870: 870,\n",
       " 871: 871,\n",
       " 872: 872,\n",
       " 873: 873,\n",
       " 874: 874,\n",
       " 875: 875,\n",
       " 876: 876,\n",
       " 877: 877,\n",
       " 878: 878,\n",
       " 879: 879,\n",
       " 880: 880,\n",
       " 881: 881,\n",
       " 882: 882,\n",
       " 883: 883,\n",
       " 884: 884,\n",
       " 885: 885,\n",
       " 886: 886,\n",
       " 887: 887,\n",
       " 888: 888,\n",
       " 889: 889,\n",
       " 890: 890,\n",
       " 891: 891,\n",
       " 892: 892,\n",
       " 893: 893,\n",
       " 894: 894,\n",
       " 895: 895,\n",
       " 896: 896,\n",
       " 897: 897,\n",
       " 898: 898,\n",
       " 899: 899,\n",
       " 900: 900,\n",
       " 901: 901,\n",
       " 902: 902,\n",
       " 903: 903,\n",
       " 904: 904,\n",
       " 905: 905,\n",
       " 906: 906,\n",
       " 907: 907,\n",
       " 908: 908,\n",
       " 909: 909,\n",
       " 910: 910,\n",
       " 911: 911,\n",
       " 912: 912,\n",
       " 913: 913,\n",
       " 914: 914,\n",
       " 915: 915,\n",
       " 916: 916,\n",
       " 917: 917,\n",
       " 918: 918,\n",
       " 919: 919,\n",
       " 920: 920,\n",
       " 921: 921,\n",
       " 922: 922,\n",
       " 923: 923,\n",
       " 924: 924,\n",
       " 925: 925,\n",
       " 926: 926,\n",
       " 927: 927,\n",
       " 928: 928,\n",
       " 929: 929,\n",
       " 930: 930,\n",
       " 931: 931,\n",
       " 932: 932,\n",
       " 933: 933,\n",
       " 934: 934,\n",
       " 935: 935,\n",
       " 936: 936,\n",
       " 937: 937,\n",
       " 938: 938,\n",
       " 939: 939,\n",
       " 940: 940,\n",
       " 941: 941,\n",
       " 942: 942,\n",
       " 943: 943,\n",
       " 944: 944,\n",
       " 945: 945,\n",
       " 946: 946,\n",
       " 947: 947,\n",
       " 948: 948,\n",
       " 949: 949,\n",
       " 950: 950,\n",
       " 951: 951,\n",
       " 952: 952,\n",
       " 953: 953,\n",
       " 954: 954,\n",
       " 955: 955,\n",
       " 956: 956,\n",
       " 957: 957,\n",
       " 958: 958,\n",
       " 959: 959,\n",
       " 960: 960,\n",
       " 961: 961,\n",
       " 962: 962,\n",
       " 963: 963,\n",
       " 964: 964,\n",
       " 965: 965,\n",
       " 966: 966,\n",
       " 967: 967,\n",
       " 968: 968,\n",
       " 969: 969,\n",
       " 970: 970,\n",
       " 971: 971,\n",
       " 972: 972,\n",
       " 973: 973,\n",
       " 974: 974,\n",
       " 975: 975,\n",
       " 976: 976,\n",
       " 977: 977,\n",
       " 978: 978,\n",
       " 979: 979,\n",
       " 980: 980,\n",
       " 981: 981,\n",
       " 982: 982,\n",
       " 983: 983,\n",
       " 984: 984,\n",
       " 985: 985,\n",
       " 986: 986,\n",
       " 987: 987,\n",
       " 988: 988,\n",
       " 989: 989,\n",
       " 990: 990,\n",
       " 991: 991,\n",
       " 992: 992,\n",
       " 993: 993,\n",
       " 994: 994,\n",
       " 995: 995,\n",
       " 996: 996,\n",
       " 997: 997,\n",
       " 998: 998,\n",
       " 999: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_cdvi = pd.DataFrame(\n",
    "    sorted(t6_cont['cont_descriptor_vector_id'].drop_duplicates())\n",
    ")[0].to_dict()# .reset_index()\n",
    "real_cdvi = {v:k for k,v in real_cdvi.items()}\n",
    "real_cdvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mgd['real_cont_descriptor_vector_id'] = df_mgd['cont_descriptor_vector_id'].map(real_cdvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdvi_fit = np.array(list(set(df_mgd.query('fold_split == 0')['real_cont_descriptor_vector_id'])))\n",
    "cdvi_eval = np.array(list(set(df_mgd.query('fold_split == 1')['real_cont_descriptor_vector_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1034,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdvi_fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdvi_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0, ..., 10076, 10076, 10076], dtype=int32),\n",
       " array([ 63,  64,  65, ..., 195, 220, 252], dtype=int32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_fva.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10077x285 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 184789 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_fva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10077x285 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 184789 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_fva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## CP stuff ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/285 [00:00<?, ?it/s]/home/rama.jabal/.conda/envs/melloddy_tuner_regression/lib/python3.6/site-packages/ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/rama.jabal/.conda/envs/melloddy_tuner_regression/lib/python3.6/site-packages/ipykernel_launcher.py:70: RuntimeWarning: invalid value encountered in long_scalars\n",
      " 36%|███▌      | 102/285 [00:00<00:01, 178.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 251/285 [00:01<00:00, 187.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n",
      "division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:01<00:00, 186.14it/s]\n"
     ]
    }
   ],
   "source": [
    "e_inacts = []\n",
    "e_acts = []\n",
    "val_inacts = []\n",
    "val_acts = []\n",
    "lit_val_inacts = []\n",
    "lit_val_acts = []\n",
    "unis = []\n",
    "idxs = []\n",
    "n_acts = []\n",
    "n_inacts = []\n",
    "ncms_fva_fit_dict = {}\n",
    "labels_fva_fit_dict = {}\n",
    "\n",
    "\n",
    "for col in tqdm(list(np.unique(preds_fva.nonzero()[1]))):\n",
    "    try: \n",
    "        row_idx_preds_fit = np.intersect1d(\n",
    "            preds_fva[:,col].nonzero()[0]\n",
    "            ,cdvi_fit\n",
    "        )\n",
    "        row_idx_preds_eval = np.intersect1d(\n",
    "            preds_fva[:,col].nonzero()[0]\n",
    "            ,cdvi_eval\n",
    "        )\n",
    "        preds_fva_col = preds_fva[row_idx_preds_fit,col].toarray().squeeze()\n",
    "        preds_fte_col = preds_fva[row_idx_preds_eval,col].toarray().squeeze()\n",
    "        row_idx_labels_fit = np.intersect1d(\n",
    "            labels[:,col].nonzero()[0]\n",
    "            ,cdvi_fit\n",
    "        )\n",
    "        row_idx_labels_eval = np.intersect1d(\n",
    "            labels[:,col].nonzero()[0]\n",
    "            ,cdvi_eval\n",
    "        )\n",
    "        \n",
    "        labels_fva_col = labels[row_idx_labels_fit,col].toarray().squeeze()\n",
    "        labels_fva_col = np.where(labels_fva_col == -1,0,1)\n",
    "        labels_fte_col = labels[row_idx_labels_eval,col].toarray().squeeze()\n",
    "        labels_fte_col = np.where(labels_fte_col == -1,0,1)\n",
    "        \n",
    "\n",
    "\n",
    "        ncms_fva = prob_ncm(preds_fva_col, labels_fva_col)\n",
    "        ncms_fva_fit_dict[str(col)] = ncms_fva.tolist()  # use tolist() to avoid difficulties with the serialisation\n",
    "        labels_fva_fit_dict[str(col)] = labels_fva_col.tolist() # use tolist() to avoid difficulties with the serialisation\n",
    "        #ncms_test_0 = prob_ncm(preds_fte_col, labels_fte_col)\n",
    "        #ncms_test_1 = prob_ncm(preds_fte_col, labels_fte_col)\n",
    "        ncms_test_0 = prob_ncm(preds_fte_col, np.repeat(0.,len(preds_fte_col)))\n",
    "        ncms_test_1 = prob_ncm(preds_fte_col, np.repeat(1.,len(preds_fte_col)))\n",
    "\n",
    "        p0, p1 = micp(ncms_fva,labels_fva_col,ncms_test_0,ncms_test_1,randomized=False)\n",
    "\n",
    "        cp_test = [cp_label_predictor(pe0, pe1, eps) for pe0, pe1 in zip(p0,p1)]\n",
    "        certain_idcs = np.where((np.array(cp_test) == '0') | (np.array(cp_test) == '1'))[0]\n",
    "        idx_uncertain_none = np.where([e == 'uncertain none' for e in cp_test])[0]\n",
    "        idx_uncertain_both = np.where([e == 'uncertain both' for e in cp_test])[0]\n",
    "        idx_inact = np.where(labels_fte_col == 0)[0]\n",
    "        idx_inact_certain = np.intersect1d(idx_inact,certain_idcs)\n",
    "        idx_inact_both = np.intersect1d(idx_inact,idx_uncertain_both)\n",
    "        idx_act = np.where(labels_fte_col == 1)[0]\n",
    "        idx_act_certain = np.intersect1d(idx_act,certain_idcs)\n",
    "        idx_act_both = np.intersect1d(idx_act,idx_uncertain_both)\n",
    "\n",
    "        # efficiency \n",
    "        efficiency_inact = len(idx_inact_certain) / len(idx_inact)\n",
    "        efficiency_act = len(idx_act_certain) / len(idx_act)\n",
    "\n",
    "        # validity \n",
    "        validity_inact = \\\n",
    "             np.sum(np.array(cp_test)[idx_inact_certain] == labels_fte_col[idx_inact_certain].astype(str)) / \\\n",
    "             len(np.array(cp_test)[idx_inact_certain])\n",
    "        validity_act = \\\n",
    "            np.sum(np.array(cp_test)[idx_act_certain] == labels_fte_col[idx_act_certain].astype(str)) / \\\n",
    "            len(np.array(cp_test)[idx_act_certain])\n",
    "\n",
    "        # literature validity \n",
    "        literature_validity_inact = \\\n",
    "             (np.sum(np.array(cp_test)[idx_inact_certain] == labels_fte_col[idx_inact_certain].astype(str)) \\\n",
    "             + len(idx_inact_both)) / \\\n",
    "             len(idx_inact)\n",
    "        literature_validity_act = \\\n",
    "            (np.sum(np.array(cp_test)[idx_act_certain] == labels_fte_col[idx_act_certain].astype(str)) \\\n",
    "            + len(idx_act_both)) / \\\n",
    "            len(idx_act)\n",
    "\n",
    "\n",
    "        uni = np.unique(cp_test)\n",
    "\n",
    "        e_inacts.append(efficiency_inact)\n",
    "        e_acts.append(efficiency_act)\n",
    "        val_inacts.append(validity_inact)\n",
    "        val_acts.append(validity_act)\n",
    "        lit_val_inacts.append(literature_validity_inact)\n",
    "        lit_val_acts.append(literature_validity_act)\n",
    "        unis.append(str(list(uni)))\n",
    "        idxs.append(col)\n",
    "        n_acts.append(len(idx_act))\n",
    "        n_inacts.append(len(idx_inact))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4097,  2056,  4105,  2062,  2063,    21,  4117,  4119,  2075,\n",
       "          29,  6180,  4133,  6182,  8230,  8232,  8231,    45,  6191,\n",
       "        8240,  4143,  6194,  8245,  2108,  4159,  4165,    70,  8265,\n",
       "        8266,  2124,  2125,  8269,    79,  1237,  6226,  6227,  8276,\n",
       "        8277,  2134,  1238,  4184,  6233,    90,  2139,  1239,  1240,\n",
       "        1241,  4199,  2152,   104,  2154,  1243,  8303,  8304,  8302,\n",
       "        4210,  1244,   113,   110,  4214,  4215,  2170,  2175,  6273,\n",
       "        4227,  8324,  4229,   132,  6280,  3284,  2190,   145,   148,\n",
       "        3286,  2200,   155,  8355,   164,  2212,  6139,  4264,   167,\n",
       "        4267,  8365,   173,  6319,   179,   180,  6326,  6328,   194,\n",
       "        8400,  8402,   210,  8406,   214,  6359,  2265,  2266,   215,\n",
       "        6368,  4321,  4324,  4327,  4331,   236,  8432,  8433,  8434,\n",
       "        8435,  2304,  8449,  4354,  4355,  2308,  4356,  8459,  2318,\n",
       "        2322,  2323,  8478,  6435,  4389,   296,   297,  8490,  4394,\n",
       "         303,   309,   310,  6455,   312,  4409,   313,  2362,  8506,\n",
       "        8509,  2366,  7390,  4416,   316,   322,  4419,  2376,  6473,\n",
       "         330,   331,  2380,   332,  4431,   341,   342,   344,  8536,\n",
       "        4442,  6492,   348,  8543,  6496,  6500,   357,  6503,  8554,\n",
       "        2411,  4461,  4462,  2415,  8563,   378,  4475,  4477,   381,\n",
       "        4483,   387,  4485,  6534,   392,  4493,  4494,   399,  4501,\n",
       "        6554,  2459,   410,  6561,  2465,  8611,  8612,  8614,  4520,\n",
       "        8621,  4526,  6575,  2480,  8625,  6576,   431,  4533,  8630,\n",
       "        8635,  6588,   446,  2501,  2502,  2507,  2510,  4559,  6606,\n",
       "        6610,  8664,  8666,   486,  2535,  2536,  6635,   491,  8685,\n",
       "        2541,  8692,   503,  2552,  4601,   507,  2557,  4610,   516,\n",
       "        2565,   517,   520,  8713,  2572,  6668,  8718,  6671,  2581,\n",
       "        4631,  2586,  4634,  6686,  4645,  2597,  6695,  8745,  6699,\n",
       "        4653,  8751,  6705,  8754,   563,  6710,  2615,   566,   573,\n",
       "        2622,  4671,  2624,  4673,  6725,  6727,  4680,  4681,  2636,\n",
       "        6733,  4687,  6737,  8786,   599,  2648,  2647,  8797,  8799,\n",
       "        6752,  2658,  2659,  8804,  8805,  8806,  8807,  8810,   619,\n",
       "        2669,  2670,  2671,  2672,  8814,  8821,  6776,   633,  8825,\n",
       "         636,  4733,  4738,  2693,  2694,  6790,  8840,  8841,  4744,\n",
       "        6794,  8842,  6797,  2701,  2708,  4759,  2712,  4761,  4762,\n",
       "        4766,   673,   674,   676,  4779,  4782,  4783,  2740,   694,\n",
       "        8889,  2748,  6845,  4798,  8893,  6848,  4802,  8901,  2759,\n",
       "        4810,  8907,  2764,  8906,  8918,  6871,   731,  8935,  4841,\n",
       "        8948,  2811,  2812,  2813,   766,  6911,  3816,  4866,  6924,\n",
       "        6926,  4879,  4881,  8977,  8979,  8980,   789,  2837,   793,\n",
       "        4892,  8988,  6942,  8992,  6944,  6948,   806,  4903,  6951,\n",
       "        6954,  6955,  2858,  2861,  2862,  4910,  9008,   813,  2866,\n",
       "        6963,   817,  4916,  4913,  6970,  6976,  4932,  6992,  2897,\n",
       "        6998,   855,   857,  4955,  7003,  2909,   862,   865,   868,\n",
       "        4969,  7018,  4974,  4976,  7027,   885,  2934,   886,  7038,\n",
       "        7039,  7040,   899,   901,  2950,  2956,  7053,  7052,  2958,\n",
       "        9104,  5009,  7059,  5011,  7061,  7063,  5016,  9114,  7067,\n",
       "         928,  9123,  5029,  9129,   938,  5037,  5038,  9134,   941,\n",
       "        9133,  2996,  5047,  7096,  9147,  5056,  5060,  3016,  5064,\n",
       "        3539,   974,  3022,   979,  7124,  3030,  5080,  7135,   991,\n",
       "        9186,  7140,  5097,  7146,  9199,  5107,  3060,  7157,  5114,\n",
       "        5115,  3069,  3070,  7168,  3073,  5123,  3075,  7175,  5133,\n",
       "        1038,  1039,  3087,  1040,  7186,  1042,  9236,  5142,  1050,\n",
       "        5147,  5148,  1053,  1055,  3104,  5156,  3109,  1064,  7215,\n",
       "        9267,  3124,  9269,  1079,  1080,  9274,  3133,  1086,  9279,\n",
       "        7233,  9284,  9287,  9288,  7239,  9290,  1099,  3148,  9293,\n",
       "        1100,  7246,  7247,  7242,  3151,  3156,  9301,  3158,  7257,\n",
       "        5210,  1116,  1120,  1121,  7270,  9319,  5227,  9324,  7277,\n",
       "        1133,  3182,  5232,  9330,  5236,  9333,  5242,  3196,  3197,\n",
       "        5250,  5251,  5252,  9354,  5263,  7317,  7318,  1173,  5274,\n",
       "        3226,  5280,  3233,  7332,  3236,  5286,  7336,  7337,  9385,\n",
       "        5291,  3246,  9394,  1205,  7350,  9400,  1209,  3257,  3259,\n",
       "        1212,  1208,  7358,  5311,  9406,  9409,  7362,  9411,  1219,\n",
       "        7363,  1218,  5319,  1217,  5312,  1227,  3276,  1230,  1231,\n",
       "        1232,  1233,  1234,  1235,  9428,  5333,  5334,  1236,  9432,\n",
       "        5337,  3290,  1242,  5340,  7388,  1245,  3295,  5344,  7393,\n",
       "        5345,  1248,  1247,  7397,  1246,  1249,  3296,  5359,  3312,\n",
       "        7410,  5362,  3316,  1266,  5367,  1273,  1274,  1278,  3327,\n",
       "        1281,  5378,  3342,  3349,  1302,  3351,  1303,  5402,  1309,\n",
       "        7457,  7458,  3364,  5414,  3368,  1325,  5422,  1326,  1485,\n",
       "        7473,  3378,  3377,  5428,  7472,  3382,  5432,  7480,  9535,\n",
       "        3395,  7492,  3398,  3400,  3402,  9547,  1356,  1491,  9550,\n",
       "        3407,  7505,  3410,  9552,  3412,  3413,  9558,  5460,  3409,\n",
       "        1374,  5471,  9569,  3532,  1388,  7533,  5485,  9583,  9586,\n",
       "        7538,  9593,  9597,  5504,  3457,  9602,  1411,  1410,  1413,\n",
       "        1414,  3456,  1417,  1418,  1419,  3470,  5518,  7568,  1424,\n",
       "        1426,  7571,  1423,  5521,  1430,  3479,  3480,  5529,  5530,\n",
       "        3485,  9630,  9631,  3488,  3490,  3493,  9639,  9640,  9641,\n",
       "        9642,  5553,  1458,  1463,  7608,  9658,  1467,  5564,  5562,\n",
       "        1471,  1472,  7615,  1474,  1475,  3528,  1481,  1483,  1484,\n",
       "        9677,  9678,  9676,  3533,  9681,  1489,  7633,  1490,  7635,\n",
       "        9686,  1495,  1496,  7634,  1498,  9690,  3543,  9694,  3551,\n",
       "        3552,  7649,  9698,  1503,  5604,  9702,  9703,  9704,  7664,\n",
       "        1521,  1522,  3571,  5620,  3574,  3576,  1529,  1531,  7632,\n",
       "        1536,  1537,  3586,  5635,  9732,  5637,  5636,  7687,  5641,\n",
       "        7689,  5643,  5644,  3596,  3598,  3593,  3601,  5650,  9750,\n",
       "        5656,  1564,  5661,  7710,  7709,  5663,  3617,  9762,  7715,\n",
       "        9765,  9768,  3631,  9777,  1585,  1587,  9781,  5686,  5687,\n",
       "        9782,  5689,  1593,  5693,  3646,  3645,  9794,  7748,  3654,\n",
       "        1607,  5706,  7754,  3664,  5716,  1621,  5718,  9817,  5725,\n",
       "        3678,  9823,  3680,  5729,  7778,  5730,  5734,  7782,  3688,\n",
       "        1641,  1642,  5738,  1643,  9838,  1647,  5743,  9839,  1651,\n",
       "        1652,  3699,  5752,  5757,  5758,  1663,  9855,  5765,  1670,\n",
       "        1671,  9866,  1675,  1679,  7824,  3731,  1686,  3737,  7838,\n",
       "        7839,  7840,  1701,  7846,  7849,  3754,  5804,  5805,  5807,\n",
       "        1712,  3768,  9913,  1722,  9916,  5822,  9920,  1737,  3790,\n",
       "        9934,  9936,  5841,  3794,  5843,  5844,  9941,  1742,  1754,\n",
       "        3804,  3807,  7912,  9961,  1768,  3819,  3820,  3818,  3817,\n",
       "        9967,  5872,  5871,  5874,  5875,  3827,  7922,  3830,  3826,\n",
       "        7929,  1790,  7940,  9992,  5896,  1802,  9995,  5897,  7951,\n",
       "       10000,  5906, 10004,  5909,  1813,  7962,  7963,  7967,  5920,\n",
       "        7969, 10018,  7973,  3878,  5927,  1832,  5928,  5929,  1831,\n",
       "        7974,  1838,  5939,  7991,  1848,  1851,  1852, 10045,  1853,\n",
       "       10048,  1859,  5957,  8019,  8020,  3925,  8022,  5974,  8028,\n",
       "        3939,  3940,  3944,  3946,  5999,  1906,  8051,  3960,  6011,\n",
       "        3964,  6012,  3966,  3967,  6017,  6019,  6029,  3982,  6030,\n",
       "        3983,  8081,  6045,  1950,  8101,  1958,  6055,  1963,  1964,\n",
       "        1966,  8112,  8115,  4022,  1974,  8122,  8123,  8124,  1978,\n",
       "        8126,  6079,  6081,  4034,  4035,  4044,  4045,  8143,  4048,\n",
       "        8144,  8150,  2009,  8154,  6108,  2014,  2015,  4067,  6121,\n",
       "        6123,  8172,  2029,  8178,  2036,  2037,  2039,  4089,  6138,\n",
       "        2043,  4093])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdvi_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  20,  195,  666,  763, 1387, 1395, 1506, 1547, 1749, 1782, 1820,\n",
       "       1907, 1991, 2086, 2666, 2867, 3145, 4014, 4051, 4052, 4087, 4163,\n",
       "       4305, 4664, 4913, 5029, 5237, 5502, 5626, 5792, 5808, 6032, 6396,\n",
       "       6909, 6961, 7162, 7231, 7583, 7693, 7819, 8000, 8099, 8142, 8285,\n",
       "       8319, 8474, 8771, 9225, 9794, 9817, 9909, 9943, 9944, 9998],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the inputs to the micp() function in order to obtain the CP labels for the inference predictions\n",
    "import json \n",
    "with open('./cp/ncms_fva_fit_dict.json', 'w') as fp:\n",
    "\tjson.dump(ncms_fva_fit_dict, fp)\n",
    "with open('./cp/labels_fva_dict.json', 'w') as fp:\n",
    "\tjson.dump(labels_fva_fit_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'n_inactives_eval':n_inacts\n",
    "    ,'n_actives_eval':n_acts\n",
    "    ,'efficiency_0' : e_inacts\n",
    "    ,'efficiency_1':e_acts\n",
    "    ,'validity_0':val_inacts\n",
    "    ,'validity_1':val_acts\n",
    "    ,'literature_validity_0':lit_val_inacts\n",
    "    ,'literature_validity_1':lit_val_acts\n",
    "    ,'valuess':unis\n",
    "    ,'index':idxs\n",
    "}).to_csv('./cp/summary_eps_' + str(eps) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_inactives_eval</th>\n",
       "      <th>n_actives_eval</th>\n",
       "      <th>efficiency_0</th>\n",
       "      <th>efficiency_1</th>\n",
       "      <th>validity_0</th>\n",
       "      <th>validity_1</th>\n",
       "      <th>literature_validity_0</th>\n",
       "      <th>literature_validity_1</th>\n",
       "      <th>valuess</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['1', 'uncertain both']</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['uncertain both']</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_inactives_eval  n_actives_eval  efficiency_0  efficiency_1  validity_0  \\\n",
       "0                  10               4      0.000000      0.000000         NaN   \n",
       "1                   9               7      0.000000      0.000000         NaN   \n",
       "2                   9               6      0.000000      0.000000         NaN   \n",
       "3                  11               4      0.000000      0.000000         NaN   \n",
       "4                  12               7      0.000000      0.000000         NaN   \n",
       "..                ...             ...           ...           ...         ...   \n",
       "277                59              26      0.033898      0.076923         0.0   \n",
       "278                 7              13      0.000000      0.000000         NaN   \n",
       "279                 6               3      0.000000      0.000000         NaN   \n",
       "280                 3               9      0.000000      0.000000         NaN   \n",
       "281                 2               3      0.000000      0.000000         NaN   \n",
       "\n",
       "     validity_1  literature_validity_0  literature_validity_1  \\\n",
       "0           NaN               1.000000                    1.0   \n",
       "1           NaN               1.000000                    1.0   \n",
       "2           NaN               1.000000                    1.0   \n",
       "3           NaN               1.000000                    1.0   \n",
       "4           NaN               1.000000                    1.0   \n",
       "..          ...                    ...                    ...   \n",
       "277         1.0               0.966102                    1.0   \n",
       "278         NaN               1.000000                    1.0   \n",
       "279         NaN               1.000000                    1.0   \n",
       "280         NaN               1.000000                    1.0   \n",
       "281         NaN               1.000000                    1.0   \n",
       "\n",
       "                     valuess  index  \n",
       "0         ['uncertain both']      0  \n",
       "1         ['uncertain both']      1  \n",
       "2         ['uncertain both']      2  \n",
       "3         ['uncertain both']      3  \n",
       "4         ['uncertain both']      4  \n",
       "..                       ...    ...  \n",
       "277  ['1', 'uncertain both']    280  \n",
       "278       ['uncertain both']    281  \n",
       "279       ['uncertain both']    282  \n",
       "280       ['uncertain both']    283  \n",
       "281       ['uncertain both']    284  \n",
       "\n",
       "[282 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'n_inactives_eval':n_inacts\n",
    "    ,'n_actives_eval':n_acts\n",
    "    ,'efficiency_0' : e_inacts\n",
    "    ,'efficiency_1':e_acts\n",
    "    ,'validity_0':val_inacts\n",
    "    ,'validity_1':val_acts\n",
    "    ,'literature_validity_0':lit_val_inacts\n",
    "    ,'literature_validity_1':lit_val_acts\n",
    "    ,'valuess':unis\n",
    "    ,'index':idxs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mellody Tuner",
   "language": "python",
   "name": "melloddy_tuner_regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
